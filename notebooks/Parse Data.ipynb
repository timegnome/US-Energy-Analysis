{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import gc\n",
    "import re\n",
    "# import difflib as diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# totalEngJson = pd.read_json('TOTAL.json')\n",
    "# Can't read file as a json and must be parsed as a text\n",
    "# Columns to create must include:\n",
    "# series_id, name, units, f, start, end, last_updated, data\n",
    "# Data is a list object with list objects containing 2 values\n",
    "# Year/Date, unit amount\n",
    "# Two types of json objects: Annual and monthly\n",
    "# This is for the same recorded energy name\n",
    "# Create a new csv of both total dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2019', '327.231') 2019 0\n",
      "('2018', '323.058') 2018 0\n",
      "('2017', '322.703') 2017 0\n",
      "('2016', '326.164') 2016 0\n",
      "('2015', '360.023') 2015 0\n",
      "('2014', '356.525') 2014 0\n",
      "('2013', '343.542') 2013 0\n",
      "('2012', '355.16') 2012 0\n",
      "('2011', '391.446') 2011 0\n",
      "('2010', '391.186') 2010 0\n",
      "('2009', '395.119') 2009 0\n",
      "('2008', '383.906') 2008 0\n",
      "('2007', '381.217') 2007 0\n",
      "('2006', '399.722') 2006 0\n",
      "('2005', '446.955') 2005 0\n",
      "('2004', '469.753') 2004 0\n",
      "('2003', '495.513') 2003 0\n",
      "('2002', '443.627') 2002 0\n",
      "('2001', '507.839') 2001 0\n",
      "('2000', '490.457') 2000 0\n",
      "('1999', '437.988') 1999 9\n",
      "('1998', '428.401') 1998 9\n",
      "('1997', '443.434') 1997 9\n",
      "('1996', '482.505') 1996 9\n",
      "('1995', '478.472') 1995 9\n",
      "('1994', '500.513') 1994 9\n",
      "('1993', '493.037') 1993 9\n",
      "('1992', '506.666') 1992 9\n",
      "('1991', '517.367') 1991 9\n",
      "('1990', '535.83') 1990 9\n",
      "('1989', '573.707') 1989 9\n",
      "('1988', '599.889') 1988 9\n",
      "('1987', '607.483') 1987 9\n",
      "('1986', '623.384') 1986 9\n",
      "('1985', '630.887') 1985 9\n",
      "('1984', '735.168') 1984 9\n",
      "('1983', '651.465') 1983 9\n",
      "('1982', '439.656') 1982 9\n",
      "('1981', '457.123') 1981 9\n",
      "('1980', '517.728') 1980 9\n",
      "('1979', '583.512') 1979 9\n",
      "('1978', '665.642') 1978 9\n",
      "('1977', '676.089') 1977 9\n",
      "('1976', '655.903') 1976 9\n",
      "('1975', '586.643') 1975 9\n",
      "('1974', '595.633') 1974 9\n",
      "('1973', '643.586') 1973 9\n",
      "('1972', '631.686') 1972 9\n",
      "('1971', '594.709') 1971 9\n",
      "('1970', '587.492') 1970 9\n",
      "('1969', '573.017') 1969 9\n",
      "('1968', '573.681') 1968 9\n",
      "('1967', '552.321') 1967 9\n",
      "('1966', '528.904') 1966 9\n",
      "('1965', '534.45') 1965 9\n",
      "('1964', '509.192') 1964 9\n",
      "('1963', '523.207') 1963 9\n",
      "('1962', '525.939') 1962 9\n",
      "('1961', '504.34') 1961 9\n",
      "('1960', '493.587') 1960 9\n",
      "('1959', '422.342') 1959 9\n",
      "('1958', '423.594') 1958 9\n",
      "('1957', '394.859') 1957 9\n",
      "('1956', '397.615') 1956 9\n",
      "('1955', '377.029') 1955 9\n",
      "('1954', '341.392') 1954 9\n",
      "('1953', '306.482') 1953 9\n",
      "('1952', '304.024') 1952 9\n",
      "('1951', '292.689') 1951 9\n",
      "('1950', '261.805') 1950 9\n",
      "('1949', '221.006') 1949 9\n"
     ]
    }
   ],
   "source": [
    "# Two dataframes\n",
    "# series_id, name, units, f, start, end, last_updated, date, amount\n",
    "# {\"series_id\":\"([\\w\\.]+)\",\"name\":\"([\\w \\,]+)\",\"units\":\"([\\w \\,]+)\",\"f\":\"(\\w+)\",\"start\":\".+\",\"data\":(?:(\\[(\"\\d+\",[\\d\\.]+)\\])(?:,|))}\n",
    "totAnnual = pd.DataFrame(columns =['series_id', 'name', 'units',\n",
    "                                   'f',\n",
    "                                   'date', 'amount'])\n",
    "totMonthly = pd.DataFrame(columns =['series_id', 'name', 'units',\n",
    "                                   'f',\n",
    "                                   'date', 'amount'])\n",
    "regex = r'{\"series_id\":\"([\\w\\.]+)\",\"name\":\"([\\w \\,]+)\",\"units\":\"([\\w \\,]+)\",\"f\":\"(\\w+)\",\"start\":\".+\",\"data\":\\[(?:\\[\"\\d+\",[\\d\\.]+\\](?:,|))+\\]}'\n",
    "dataRegex = r'(?:\\[\"([\\w\\d]+)\",((?:[\\d\\.]+)|(?:\\w+))\\](?:,|))'\n",
    "\n",
    "with open('../data/raw/TOTAL.json','r') as file:\n",
    "    line = file.readline()\n",
    "    while line:\n",
    "        match = re.findall(regex,line)\n",
    "        data =  re.findall(dataRegex,line)\n",
    "        try:\n",
    "            if match[0][3] == 'A':\n",
    "                for d in data:\n",
    "                    totAnnual.loc[len(totAnnual.index)] = ([match[0][0],\n",
    "                        match[0][1],match[0][2],match[0][3],d[0],d[1]])\n",
    "            else:\n",
    "                for d in data:\n",
    "                    totMonthly.loc[len(totMonthly.index)] =([match[0][0],\n",
    "                        match[0][1],match[0][2],match[0][3],d[0],d[1]])\n",
    "        except:\n",
    "            None\n",
    "        line = file.readline()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totMonthly.to_csv('../data/processed/TOTALM.csv',index = False)\n",
    "totAnnual.to_csv('../data/processed/TOTALA.csv',index = False)\n",
    "del totAnnual\n",
    "del totMonthly\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "totAnnual = pd.DataFrame(columns =['series_id', 'name', 'units',\n",
    "                                   'f',\n",
    "                                   'date', 'amount'])\n",
    "totMonthly = pd.DataFrame(columns =['series_id', 'name', 'units',\n",
    "                                   'f',\n",
    "                                   'date', 'amount'])\n",
    "energyRegex = r'{\"series_id\":\"([\\w\\.\\-]+)\",\"name\":\"([\\w \\,\\:\\(\\)-]+)\",\"units\":\"([\\w \\,]+)\",\"f\":\"(\\w+)\",\"description\":\".+\",\"iso3166\":\"([\\w\\-]+)\",\"geography\":\".+\",\"'\n",
    "with open('../data/raw/COAL.json','r') as file:\n",
    "    line = file.readline()\n",
    "    while line:\n",
    "        match = re.findall(energyRegex,line)\n",
    "        data =  re.findall(dataRegex,line)\n",
    "        try:\n",
    "            if match[0][3] == 'A':\n",
    "                for d in data:\n",
    "                    totAnnual.loc[len(totAnnual.index)] = ([match[0][0],\n",
    "                        match[0][1],match[0][2],match[0][3],d[0],d[1]])\n",
    "            else:\n",
    "                for d in data:\n",
    "                    totMonthly.loc[len(totMonthly.index)] =([match[0][0],\n",
    "                        match[0][1],match[0][2],match[0][3],d[0],d[1]])\n",
    "        except:\n",
    "            None\n",
    "        line = file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totMonthly.to_csv('../data/processed/CoalM.csv',index = False)\n",
    "totAnnual.to_csv('../data/processed/CoalA.csv',index = False)\n",
    "del totAnnual\n",
    "del totMonthly\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "totAnnual = pd.DataFrame(columns =['series_id', 'name', 'units',\n",
    "                                   'f',\n",
    "                                   'date', 'amount'])\n",
    "totMonthly = pd.DataFrame(columns =['series_id', 'name', 'units',\n",
    "                                   'f',\n",
    "                                   'date', 'amount'])\n",
    "totDaily = pd.DataFrame(columns =['series_id', 'name', 'units',\n",
    "                                   'f',\n",
    "                                   'date', 'amount'])\n",
    "totWeekly = pd.DataFrame(columns =['series_id', 'name', 'units',\n",
    "                                   'f',\n",
    "                                   'date', 'amount'])\n",
    "energyRegex = r'{\"series_id\":\"([\\w\\.\\-]+)\",\"name\":\"([\\w \\,\\:\\(\\)-]+)\",\"units\":\"([\\w \\,]+)\",\"f\":\"(\\w+)\",\"description\":\".+\",\"iso3166\":\"([\\w\\-]+)\",\"geography\":\".+\",\"'\n",
    "with open('../data/raw/NG.json','r') as file:\n",
    "    line = file.readline()\n",
    "    while line:\n",
    "        match = re.findall(energyRegex,line)\n",
    "        data =  re.findall(dataRegex,line)\n",
    "        try:\n",
    "            if match[0][3] == 'A':\n",
    "                for d in data:\n",
    "                    totAnnual.loc[len(totAnnual.index)] = ([match[0][0],\n",
    "                        match[0][1],match[0][2],match[0][3],d[0],d[1]])\n",
    "            elif match[0][3] == 'M':\n",
    "                for d in data:\n",
    "                    totMonthly.loc[len(totMonthly.index)] =([match[0][0],\n",
    "                        match[0][1],match[0][2],match[0][3],d[0],d[1]])\n",
    "            elif match[0][3] == 'W':\n",
    "                for d in data:\n",
    "                    totWeekly.loc[len(totWeekly.index)] =([match[0][0],\n",
    "                        match[0][1],match[0][2],match[0][3],d[0],d[1]])\n",
    "            else:\n",
    "                for d in data:\n",
    "                    totDaily.loc[len(totDaily.index)] =([match[0][0],\n",
    "                        match[0][1],match[0][2],match[0][3],d[0],d[1]])\n",
    "        except:\n",
    "            None\n",
    "        line = file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totMonthly.to_csv('../data/processed/NGM.csv',index = False)\n",
    "totAnnual.to_csv('../data/processed/NGA.csv',index = False)\n",
    "totWeekly.to_csv('../data/processed/NGW.csv',index = False)\n",
    "totDaily.to_csv('../data/processed/NGD.csv',index = False)\n",
    "del totAnnual\n",
    "del totMonthly\n",
    "del totDaily\n",
    "del totWeekly\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totAnnual = pd.DataFrame(columns =['series_id', 'name', 'units',\n",
    "                                   'f',\n",
    "                                   'date', 'amount'])\n",
    "totMonthly = pd.DataFrame(columns =['series_id', 'name', 'units',\n",
    "                                   'f',\n",
    "                                   'date', 'amount'])\n",
    "energyRegex = r'{\"series_id\":\"([\\w\\.\\-]+)\",\"name\":\"([\\w \\,\\:\\(\\)-]+)\",\"units\":\"([\\w \\,]+)\",\"f\":\"(\\w+)\",\"description\":\".+\",\"iso3166\":\"([\\w\\-]+)\",\"geography\":\".+\",\"'\n",
    "with open('../data/raw/SEDS.json','r') as file:\n",
    "    line = file.readline()\n",
    "    while line:\n",
    "        match = re.findall(energyRegex,line)\n",
    "        data =  re.findall(dataRegex,line)\n",
    "        try:\n",
    "            if match[0][3] == 'A':\n",
    "                for d in data:\n",
    "                    totAnnual.loc[len(totAnnual.index)] = ([match[0][0],\n",
    "                        match[0][1],match[0][2],match[0][3],d[0],d[1]])\n",
    "            else:\n",
    "                for d in data:\n",
    "                    totMonthly.loc[len(totMonthly.index)] =([match[0][0],\n",
    "                        match[0][1],match[0][2],match[0][3],d[0],d[1]])\n",
    "        except:\n",
    "            None\n",
    "        line = file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totMonthly.to_csv('../data/processed/SEDSM.csv',index = False)\n",
    "totAnnual.to_csv('../data/processed/SEDSA.csv',index = False)\n",
    "del totAnnual\n",
    "del totMonthly\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totAnnual = pd.DataFrame(columns =['series_id', 'name', 'units',\n",
    "                                   'f',\n",
    "                                   'date', 'amount'])\n",
    "totMonthly = pd.DataFrame(columns =['series_id', 'name', 'units',\n",
    "                                   'f',\n",
    "                                   'date', 'amount'])\n",
    "energyRegex = r'{\"series_id\":\"([\\w\\.\\-]+)\",\"name\":\"([\\w \\,\\:\\(\\)-]+)\",\"units\":\"([\\w \\,]+)\",\"f\":\"(\\w+)\",\"description\":\".+\",\"iso3166\":\"([\\w\\-]+)\",\"geography\":\".+\",\"'\n",
    "with open('../data/raw/PET_IMPORTS.json','r') as file:\n",
    "    line = file.readline()\n",
    "    while line:\n",
    "        match = re.findall(energyRegex,line)\n",
    "        data =  re.findall(dataRegex,line)\n",
    "        try:\n",
    "            if match[0][3] == 'A':\n",
    "                for d in data:\n",
    "                    totAnnual.loc[len(totAnnual.index)] = ([match[0][0],\n",
    "                        match[0][1],match[0][2],match[0][3],d[0],d[1]])\n",
    "            else:\n",
    "                for d in data:\n",
    "                    totMonthly.loc[len(totMonthly.index)] =([match[0][0],\n",
    "                        match[0][1],match[0][2],match[0][3],d[0],d[1]])\n",
    "        except:\n",
    "            None\n",
    "        line = file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totMonthly.to_csv('../data/processed/PETIM.csv',index = False)\n",
    "totAnnual.to_csv('../data/processed/PETIA.csv',index = False)\n",
    "del totAnnual\n",
    "del totMonthly\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totAnnual = pd.DataFrame(columns =['series_id', 'name', 'units',\n",
    "                                   'f',\n",
    "                                   'date', 'amount'])\n",
    "totMonthly = pd.DataFrame(columns =['series_id', 'name', 'units',\n",
    "                                   'f',\n",
    "                                   'date', 'amount'])\n",
    "totDaily = pd.DataFrame(columns =['series_id', 'name', 'units',\n",
    "                                   'f',\n",
    "                                   'date', 'amount'])\n",
    "totWeekly = pd.DataFrame(columns =['series_id', 'name', 'units',\n",
    "                                   'f',\n",
    "                                   'date', 'amount'])\n",
    "energyRegex = r'{\"series_id\":\"([\\w\\.\\-]+)\",\"name\":\"([\\w \\,\\:\\(\\)-]+)\",\"units\":\"([\\w \\,]+)\",\"f\":\"(\\w+)\",\"description\":\".+\",\"iso3166\":\"([\\w\\-]+)\",\"geography\":\".+\",\"'\n",
    "with open('../data/raw/PET.json','r') as file:\n",
    "    line = file.readline()\n",
    "    while line:\n",
    "        match = re.findall(energyRegex,line)\n",
    "        data =  re.findall(dataRegex,line)\n",
    "        try:\n",
    "            if match[0][3] == 'A':\n",
    "                for d in data:\n",
    "                    totAnnual.loc[len(totAnnual.index)] = ([match[0][0],\n",
    "                        match[0][1],match[0][2],match[0][3],d[0],d[1]])\n",
    "            elif match[0][3] == 'M':\n",
    "                for d in data:\n",
    "                    totMonthly.loc[len(totMonthly.index)] =([match[0][0],\n",
    "                        match[0][1],match[0][2],match[0][3],d[0],d[1]])\n",
    "            elif match[0][3] == 'W':\n",
    "                for d in data:\n",
    "                    totWeekly.loc[len(totWeekly.index)] =([match[0][0],\n",
    "                        match[0][1],match[0][2],match[0][3],d[0],d[1]])\n",
    "            else:\n",
    "                for d in data:\n",
    "                    totDaily.loc[len(totDaily.index)] =([match[0][0],\n",
    "                        match[0][1],match[0][2],match[0][3],d[0],d[1]])\n",
    "        except:\n",
    "            None\n",
    "        line = file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totMonthly.to_csv('../data/processed/PETM.csv',index = False)\n",
    "totAnnual.to_csv('../data/processed/PETA.csv',index = False)\n",
    "totDaily.to_csv('../data/processed/PETD.csv',index = False)\n",
    "totWeekly.to_csv('../data/processed/PETW.csv',index = False)\n",
    "del totAnnual\n",
    "del totMonthly\n",
    "del totDaily\n",
    "del totWeekly\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totAnnual = pd.DataFrame(columns =['series_id', 'name', 'units',\n",
    "                                   'f',\n",
    "                                   'date', 'amount'])\n",
    "totMonthly = pd.DataFrame(columns =['series_id', 'name', 'units',\n",
    "                                   'f',\n",
    "                                   'date', 'amount'])\n",
    "totDaily = pd.DataFrame(columns =['series_id', 'name', 'units',\n",
    "                                   'f',\n",
    "                                   'date', 'amount'])\n",
    "# totWeekly = pd.DataFrame(columns =['series_id', 'name', 'units',\n",
    "#                                    'f',\n",
    "#                                    'date', 'amount'])\n",
    "energyRegex = r'{\"series_id\":\"([\\w\\.\\-]+)\",\"name\":\"([\\w \\,\\:\\(\\)-]+)\",\"units\":\"([\\w \\,]+)\",\"f\":\"(\\w+)\",\"description\":\".+\",\"iso3166\":\"([\\w\\-]+)\",\"geography\":\".+\",\"'\n",
    "with open('../data/raw/ELEC.json','r') as file:\n",
    "    line = file.readline()\n",
    "    while line:\n",
    "        match = re.findall(energyRegex,line)\n",
    "        data =  re.findall(dataRegex,line)\n",
    "        try:\n",
    "            if match[0][3] == 'A':\n",
    "                for d in data:\n",
    "                    totAnnual.loc[len(totAnnual.index)] = ([match[0][0],\n",
    "                        match[0][1],match[0][2],match[0][3],d[0],d[1]])\n",
    "            elif match[0][3] == 'M':\n",
    "                for d in data:\n",
    "                    totMonthly.loc[len(totMonthly.index)] =([match[0][0],\n",
    "                        match[0][1],match[0][2],match[0][3],d[0],d[1]])\n",
    "#             elif match[0][3] == 'Q':\n",
    "#                 for d in data:\n",
    "#                     totWeekly.loc[len(totWeekly.index)] =([match[0][0],\n",
    "#                         match[0][1],match[0][2],match[0][3],d[0],d[1]])\n",
    "            else:\n",
    "                for d in data:\n",
    "                    totDaily.loc[len(totDaily.index)] =([match[0][0],\n",
    "                        match[0][1],match[0][2],match[0][3],d[0],d[1]])\n",
    "        except:\n",
    "            None\n",
    "        line = file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totMonthly.to_csv('../data/processed/ELECM.csv',index = False)\n",
    "totAnnual.to_csv('../data/processed/ELECA.csv',index = False)\n",
    "totDaily.to_csv('../data/processed/ELECO.csv',index = False)\n",
    "del totAnnual\n",
    "del totMonthly\n",
    "del totDaily\n",
    "# del totWeekly\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totAnnual = pd.DataFrame(columns =['series_id', 'name', 'units',\n",
    "                                   'f',\n",
    "                                   'date', 'amount'])\n",
    "emissRegex = r'{\"series_id\":\"([\\w\\.\\-]+)\",\"name\":\"([\\w \\,\\:\\(\\)-]+)\",\"units\":\"([\\w \\,]+)\",\"f\":\"(\\w+)\",\"unitsshort\":\".+\",\"iso3166\":\"([\\w\\-]+)\",\"geography\":\".+\",\"'\n",
    "with open('../data/raw/EMISS.json','r') as file:\n",
    "    line = file.readline()\n",
    "    while line:\n",
    "        match = re.findall(emissRegex,line)\n",
    "        data =  re.findall(dataRegex,line)\n",
    "        try:\n",
    "            if match[0][3] == 'A':\n",
    "                for d in data:\n",
    "                    totAnnual.loc[len(totAnnual.index)] = ([match[0][0],\n",
    "                        match[0][1],match[0][2],match[0][3],d[0],d[1]])\n",
    "        except:\n",
    "            None\n",
    "        line = file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totAnnual.to_csv('../data/processed/EMISSA.csv',index = false)\n",
    "del totAnnual\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
